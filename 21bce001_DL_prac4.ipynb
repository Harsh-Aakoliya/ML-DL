{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":3649,"databundleVersionId":46718,"sourceType":"competition"}],"dockerImageVersionId":30665,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd\n!pip install py7zr\n\nfrom py7zr import unpack_7zarchive\nimport shutil\n\nshutil.register_unpack_format('.7zip', '.7z', unpack_7zarchive)\n\nshutil.unpack_archive('/kaggle/input/cifar-10/train.7z', '/kaggle/temp/')","metadata":{"execution":{"iopub.status.busy":"2024-04-29T05:59:15.203812Z","iopub.execute_input":"2024-04-29T05:59:15.204579Z","iopub.status.idle":"2024-04-29T05:59:27.900547Z","shell.execute_reply.started":"2024-04-29T05:59:15.204545Z","shell.execute_reply":"2024-04-29T05:59:27.899301Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Requirement already satisfied: py7zr in /opt/conda/lib/python3.10/site-packages (0.21.0)\nRequirement already satisfied: texttable in /opt/conda/lib/python3.10/site-packages (from py7zr) (1.7.0)\nRequirement already satisfied: pycryptodomex>=3.16.0 in /opt/conda/lib/python3.10/site-packages (from py7zr) (3.20.0)\nRequirement already satisfied: pyzstd>=0.15.9 in /opt/conda/lib/python3.10/site-packages (from py7zr) (0.15.10)\nRequirement already satisfied: pyppmd<1.2.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from py7zr) (1.1.0)\nRequirement already satisfied: pybcj<1.1.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from py7zr) (1.0.2)\nRequirement already satisfied: multivolumefile>=0.2.3 in /opt/conda/lib/python3.10/site-packages (from py7zr) (0.2.3)\nRequirement already satisfied: inflate64<1.1.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from py7zr) (1.0.0)\nRequirement already satisfied: brotli>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from py7zr) (1.1.0)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from py7zr) (5.9.3)\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRegistryError\u001b[0m                             Traceback (most recent call last)","Cell \u001b[0;32mIn[12], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpy7zr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m unpack_7zarchive\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mshutil\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[43mshutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregister_unpack_format\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.7zip\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.7z\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munpack_7zarchive\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m shutil\u001b[38;5;241m.\u001b[39munpack_archive(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/kaggle/input/cifar-10/train.7z\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/kaggle/temp/\u001b[39m\u001b[38;5;124m'\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/shutil.py:1182\u001b[0m, in \u001b[0;36mregister_unpack_format\u001b[0;34m(name, extensions, function, extra_args, description)\u001b[0m\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m extra_args \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1181\u001b[0m     extra_args \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m-> 1182\u001b[0m \u001b[43m_check_unpack_options\u001b[49m\u001b[43m(\u001b[49m\u001b[43mextensions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1183\u001b[0m _UNPACK_FORMATS[name] \u001b[38;5;241m=\u001b[39m extensions, function, extra_args, description\n","File \u001b[0;32m/opt/conda/lib/python3.10/shutil.py:1156\u001b[0m, in \u001b[0;36m_check_unpack_options\u001b[0;34m(extensions, function, extra_args)\u001b[0m\n\u001b[1;32m   1154\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m extension \u001b[38;5;129;01min\u001b[39;00m existing_extensions:\n\u001b[1;32m   1155\u001b[0m         msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is already registered for \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m-> 1156\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m RegistryError(msg \u001b[38;5;241m%\u001b[39m (extension,\n\u001b[1;32m   1157\u001b[0m                                    existing_extensions[extension]))\n\u001b[1;32m   1159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(function):\n\u001b[1;32m   1160\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe registered function must be a callable\u001b[39m\u001b[38;5;124m'\u001b[39m)\n","\u001b[0;31mRegistryError\u001b[0m: . is already registered for \".7zip\""],"ename":"RegistryError","evalue":". is already registered for \".7zip\"","output_type":"error"}]},{"cell_type":"code","source":"import torch\nif torch.cuda.is_available():\n    device=torch.device(type=\"cuda\", index=0)\nelse:\n    device=torch.device(type=\"cpu\", index=0)\n\nprint(f'using device {device}')","metadata":{"execution":{"iopub.status.busy":"2024-04-29T05:00:03.149825Z","iopub.execute_input":"2024-04-29T05:00:03.150740Z","iopub.status.idle":"2024-04-29T05:00:06.525604Z","shell.execute_reply.started":"2024-04-29T05:00:03.150702Z","shell.execute_reply":"2024-04-29T05:00:06.524578Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"using device cuda:0\n","output_type":"stream"}]},{"cell_type":"code","source":"labels=pd.read_csv(\"/kaggle/input/cifar-10/trainLabels.csv\", header='infer')\n\nclasses=labels['label'].unique()\n\nclass_id = {}\ni=0\nfor label in classes:\n    class_id[label] = i\n    i+=1\n\nid_class = {}\n\nfor i in range(len(classes)):\n    id_class[i] = classes[i]","metadata":{"execution":{"iopub.status.busy":"2024-04-29T05:00:09.613850Z","iopub.execute_input":"2024-04-29T05:00:09.614391Z","iopub.status.idle":"2024-04-29T05:00:09.662299Z","shell.execute_reply.started":"2024-04-29T05:00:09.614359Z","shell.execute_reply":"2024-04-29T05:00:09.661551Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"print(class_id)\nprint(id_class)","metadata":{"execution":{"iopub.status.busy":"2024-04-29T05:00:12.609399Z","iopub.execute_input":"2024-04-29T05:00:12.609906Z","iopub.status.idle":"2024-04-29T05:00:12.614936Z","shell.execute_reply.started":"2024-04-29T05:00:12.609863Z","shell.execute_reply":"2024-04-29T05:00:12.613907Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"{'frog': 0, 'truck': 1, 'deer': 2, 'automobile': 3, 'bird': 4, 'horse': 5, 'ship': 6, 'cat': 7, 'dog': 8, 'airplane': 9}\n{0: 'frog', 1: 'truck', 2: 'deer', 3: 'automobile', 4: 'bird', 5: 'horse', 6: 'ship', 7: 'cat', 8: 'dog', 9: 'airplane'}\n","output_type":"stream"}]},{"cell_type":"code","source":"from torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader\nimport os\nfrom torchvision.io import read_image\nfrom torchvision.transforms import ToTensor, Normalize, Resize, Compose\n\nclass TrainDataset(Dataset):\n    def __init__(self, img, label):\n        super().__init__()\n        self.imgpath=img\n        self.labelpath=label\n        self.labels=pd.read_csv(label, header='infer')\n        self.transform=Compose([Resize((224,224), antialias=True), Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])])\n        \n    def __len__(self):\n        return self.labels.shape[0]\n    \n    def __getitem__(self,idx):\n        finalpath=os.path.join(self.imgpath,str(idx+1))+'.png'\n        img=read_image(finalpath)/255\n        img=self.transform(img)\n        label=self.labels.iloc[idx,1]\n        label=class_id[label]\n        return img,label\n\ntraindataset=TrainDataset('/kaggle/temp/train','/kaggle/input/cifar-10/trainLabels.csv')        \n        \nbatch_size=64    \ntraindataloader=DataLoader(dataset=traindataset, batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2024-04-29T05:00:14.510092Z","iopub.execute_input":"2024-04-29T05:00:14.510743Z","iopub.status.idle":"2024-04-29T05:00:17.256984Z","shell.execute_reply.started":"2024-04-29T05:00:14.510705Z","shell.execute_reply":"2024-04-29T05:00:17.255977Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"import torch.nn as nn\nfrom torchvision.models import mobilenet_v3_large, MobileNet_V3_Large_Weights\n\nmodel = mobilenet_v3_large(MobileNet_V3_Large_Weights.DEFAULT)\nprint(model)\n\nclass Prac5(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.pretrainednet=mobilenet_v3_large(weights=MobileNet_V3_Large_Weights.DEFAULT)\n        self.pretrainednet.classifier=nn.Sequential(\n            nn.Linear(in_features=960, out_features=1280, \n                   bias=True),nn.Hardswish(), \n            nn.Dropout(p=0.2, inplace=True), \n            nn.Linear(in_features=1280, out_features=10, \n                      bias=True)\n        )\n    def forward(self,x):\n        x=self.pretrainednet(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-04-29T05:00:20.421434Z","iopub.execute_input":"2024-04-29T05:00:20.422284Z","iopub.status.idle":"2024-04-29T05:00:20.903130Z","shell.execute_reply.started":"2024-04-29T05:00:20.422252Z","shell.execute_reply":"2024-04-29T05:00:20.902051Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:135: UserWarning: Using 'weights' as positional parameter(s) is deprecated since 0.13 and may be removed in the future. Please use keyword parameter(s) instead.\n  warnings.warn(\nDownloading: \"https://download.pytorch.org/models/mobilenet_v3_large-5c1a4163.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v3_large-5c1a4163.pth\n100%|██████████| 21.1M/21.1M [00:00<00:00, 126MB/s] \n","output_type":"stream"},{"name":"stdout","text":"MobileNetV3(\n  (features): Sequential(\n    (0): Conv2dNormActivation(\n      (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n      (2): Hardswish()\n    )\n    (1): InvertedResidual(\n      (block): Sequential(\n        (0): Conv2dNormActivation(\n          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n          (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n        )\n        (1): Conv2dNormActivation(\n          (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n        )\n      )\n    )\n    (2): InvertedResidual(\n      (block): Sequential(\n        (0): Conv2dNormActivation(\n          (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n        )\n        (1): Conv2dNormActivation(\n          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n          (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n        )\n        (2): Conv2dNormActivation(\n          (0): Conv2d(64, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n        )\n      )\n    )\n    (3): InvertedResidual(\n      (block): Sequential(\n        (0): Conv2dNormActivation(\n          (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n        )\n        (1): Conv2dNormActivation(\n          (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)\n          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n        )\n        (2): Conv2dNormActivation(\n          (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n        )\n      )\n    )\n    (4): InvertedResidual(\n      (block): Sequential(\n        (0): Conv2dNormActivation(\n          (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n        )\n        (1): Conv2dNormActivation(\n          (0): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)\n          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n        )\n        (2): SqueezeExcitation(\n          (avgpool): AdaptiveAvgPool2d(output_size=1)\n          (fc1): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1))\n          (fc2): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1))\n          (activation): ReLU()\n          (scale_activation): Hardsigmoid()\n        )\n        (3): Conv2dNormActivation(\n          (0): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n        )\n      )\n    )\n    (5): InvertedResidual(\n      (block): Sequential(\n        (0): Conv2dNormActivation(\n          (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n        )\n        (1): Conv2dNormActivation(\n          (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n        )\n        (2): SqueezeExcitation(\n          (avgpool): AdaptiveAvgPool2d(output_size=1)\n          (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n          (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n          (activation): ReLU()\n          (scale_activation): Hardsigmoid()\n        )\n        (3): Conv2dNormActivation(\n          (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n        )\n      )\n    )\n    (6): InvertedResidual(\n      (block): Sequential(\n        (0): Conv2dNormActivation(\n          (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n        )\n        (1): Conv2dNormActivation(\n          (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n        )\n        (2): SqueezeExcitation(\n          (avgpool): AdaptiveAvgPool2d(output_size=1)\n          (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n          (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n          (activation): ReLU()\n          (scale_activation): Hardsigmoid()\n        )\n        (3): Conv2dNormActivation(\n          (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n        )\n      )\n    )\n    (7): InvertedResidual(\n      (block): Sequential(\n        (0): Conv2dNormActivation(\n          (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n          (2): Hardswish()\n        )\n        (1): Conv2dNormActivation(\n          (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n          (2): Hardswish()\n        )\n        (2): Conv2dNormActivation(\n          (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n        )\n      )\n    )\n    (8): InvertedResidual(\n      (block): Sequential(\n        (0): Conv2dNormActivation(\n          (0): Conv2d(80, 200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n          (2): Hardswish()\n        )\n        (1): Conv2dNormActivation(\n          (0): Conv2d(200, 200, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=200, bias=False)\n          (1): BatchNorm2d(200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n          (2): Hardswish()\n        )\n        (2): Conv2dNormActivation(\n          (0): Conv2d(200, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n        )\n      )\n    )\n    (9): InvertedResidual(\n      (block): Sequential(\n        (0): Conv2dNormActivation(\n          (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n          (2): Hardswish()\n        )\n        (1): Conv2dNormActivation(\n          (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n          (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n          (2): Hardswish()\n        )\n        (2): Conv2dNormActivation(\n          (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n        )\n      )\n    )\n    (10): InvertedResidual(\n      (block): Sequential(\n        (0): Conv2dNormActivation(\n          (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n          (2): Hardswish()\n        )\n        (1): Conv2dNormActivation(\n          (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n          (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n          (2): Hardswish()\n        )\n        (2): Conv2dNormActivation(\n          (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n        )\n      )\n    )\n    (11): InvertedResidual(\n      (block): Sequential(\n        (0): Conv2dNormActivation(\n          (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n          (2): Hardswish()\n        )\n        (1): Conv2dNormActivation(\n          (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n          (1): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n          (2): Hardswish()\n        )\n        (2): SqueezeExcitation(\n          (avgpool): AdaptiveAvgPool2d(output_size=1)\n          (fc1): Conv2d(480, 120, kernel_size=(1, 1), stride=(1, 1))\n          (fc2): Conv2d(120, 480, kernel_size=(1, 1), stride=(1, 1))\n          (activation): ReLU()\n          (scale_activation): Hardsigmoid()\n        )\n        (3): Conv2dNormActivation(\n          (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(112, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n        )\n      )\n    )\n    (12): InvertedResidual(\n      (block): Sequential(\n        (0): Conv2dNormActivation(\n          (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n          (2): Hardswish()\n        )\n        (1): Conv2dNormActivation(\n          (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n          (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n          (2): Hardswish()\n        )\n        (2): SqueezeExcitation(\n          (avgpool): AdaptiveAvgPool2d(output_size=1)\n          (fc1): Conv2d(672, 168, kernel_size=(1, 1), stride=(1, 1))\n          (fc2): Conv2d(168, 672, kernel_size=(1, 1), stride=(1, 1))\n          (activation): ReLU()\n          (scale_activation): Hardsigmoid()\n        )\n        (3): Conv2dNormActivation(\n          (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(112, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n        )\n      )\n    )\n    (13): InvertedResidual(\n      (block): Sequential(\n        (0): Conv2dNormActivation(\n          (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n          (2): Hardswish()\n        )\n        (1): Conv2dNormActivation(\n          (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n          (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n          (2): Hardswish()\n        )\n        (2): SqueezeExcitation(\n          (avgpool): AdaptiveAvgPool2d(output_size=1)\n          (fc1): Conv2d(672, 168, kernel_size=(1, 1), stride=(1, 1))\n          (fc2): Conv2d(168, 672, kernel_size=(1, 1), stride=(1, 1))\n          (activation): ReLU()\n          (scale_activation): Hardsigmoid()\n        )\n        (3): Conv2dNormActivation(\n          (0): Conv2d(672, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n        )\n      )\n    )\n    (14): InvertedResidual(\n      (block): Sequential(\n        (0): Conv2dNormActivation(\n          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n          (2): Hardswish()\n        )\n        (1): Conv2dNormActivation(\n          (0): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n          (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n          (2): Hardswish()\n        )\n        (2): SqueezeExcitation(\n          (avgpool): AdaptiveAvgPool2d(output_size=1)\n          (fc1): Conv2d(960, 240, kernel_size=(1, 1), stride=(1, 1))\n          (fc2): Conv2d(240, 960, kernel_size=(1, 1), stride=(1, 1))\n          (activation): ReLU()\n          (scale_activation): Hardsigmoid()\n        )\n        (3): Conv2dNormActivation(\n          (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n        )\n      )\n    )\n    (15): InvertedResidual(\n      (block): Sequential(\n        (0): Conv2dNormActivation(\n          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n          (2): Hardswish()\n        )\n        (1): Conv2dNormActivation(\n          (0): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n          (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n          (2): Hardswish()\n        )\n        (2): SqueezeExcitation(\n          (avgpool): AdaptiveAvgPool2d(output_size=1)\n          (fc1): Conv2d(960, 240, kernel_size=(1, 1), stride=(1, 1))\n          (fc2): Conv2d(240, 960, kernel_size=(1, 1), stride=(1, 1))\n          (activation): ReLU()\n          (scale_activation): Hardsigmoid()\n        )\n        (3): Conv2dNormActivation(\n          (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n        )\n      )\n    )\n    (16): Conv2dNormActivation(\n      (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n      (2): Hardswish()\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=1)\n  (classifier): Sequential(\n    (0): Linear(in_features=960, out_features=1280, bias=True)\n    (1): Hardswish()\n    (2): Dropout(p=0.2, inplace=True)\n    (3): Linear(in_features=1280, out_features=1000, bias=True)\n  )\n)\n","output_type":"stream"}]},{"cell_type":"code","source":"def train(dataloader, model, loss, optimizer):\n    model.train()\n    track_loss=0\n    num_correct=0\n    num_param=0\n    \n    for i, (imgs, labels) in enumerate(dataloader):\n        imgs=imgs.to(device)\n        labels=labels.to(device)\n        pred=model(imgs)\n                    \n        loss_e=loss(pred,labels)\n        track_loss+=loss_e.item()\n        num_correct+=(torch.argmax(pred,dim=1)==labels).type(torch.float).sum().item()\n        \n        running_loss=round(track_loss/(i+(imgs.shape[0]/batch_size)),2)\n        running_acc=round((num_correct/((i*batch_size+imgs.shape[0])))*100,2)\n        \n        loss_e.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n        if i%100==0:\n            print(\"Batch:\", i+1, \"/\",len(dataloader), \"Running Loss:\",running_loss, \"Running Accuracy:\",running_acc)\n            \n    epoch_loss=running_loss\n    epoch_acc=running_acc\n    return epoch_loss, epoch_acc","metadata":{"execution":{"iopub.status.busy":"2024-04-29T05:00:32.943728Z","iopub.execute_input":"2024-04-29T05:00:32.944487Z","iopub.status.idle":"2024-04-29T05:00:32.956855Z","shell.execute_reply.started":"2024-04-29T05:00:32.944445Z","shell.execute_reply":"2024-04-29T05:00:32.955749Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"model=Prac5()\nmodel=model.to(device)\n\nfor param in model.pretrainednet.features.parameters():\n    param.requires_grad=False\n\nloss=nn.CrossEntropyLoss()\nlr=0.001\noptimizer=torch.optim.Adam(params=model.parameters(), lr=lr)\nn_epochs=5\n\nfor i in range(n_epochs):\n    print(\"Epoch No:\",i+1)\n    epoch_loss, epoch_acc=train(traindataloader, model, loss, optimizer)\n    print(\"Training:\", \"Epoch Loss:\", epoch_loss, \"Epoch Accuracy:\", epoch_acc)\n    print(\"--------------------------------------------------\")\n\nfor param in model.pretrainednet.features.parameters():\n    param.requires_grad=True\n\nfor i in range(n_epochs):\n    print(\"Epoch No:\",i+1)\n    train_epoch_loss, train_epoch_acc=train(traindataloader, model, loss, optimizer)\n    print(\"Training:\", \"Epoch Loss:\", train_epoch_loss, \"Epoch Accuracy:\", train_epoch_acc)\n    print(\"--------------------------------------------------\")","metadata":{"execution":{"iopub.status.busy":"2024-04-29T05:20:17.024523Z","iopub.execute_input":"2024-04-29T05:20:17.024947Z","iopub.status.idle":"2024-04-29T05:36:24.102580Z","shell.execute_reply.started":"2024-04-29T05:20:17.024916Z","shell.execute_reply":"2024-04-29T05:36:24.101551Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Epoch No: 1\nBatch: 1 / 782 Running Loss: 2.31 Running Accuracy: 7.81\nBatch: 101 / 782 Running Loss: 1.06 Running Accuracy: 63.97\nBatch: 201 / 782 Running Loss: 0.92 Running Accuracy: 67.86\nBatch: 301 / 782 Running Loss: 0.87 Running Accuracy: 69.77\nBatch: 401 / 782 Running Loss: 0.83 Running Accuracy: 71.04\nBatch: 501 / 782 Running Loss: 0.81 Running Accuracy: 71.61\nBatch: 601 / 782 Running Loss: 0.8 Running Accuracy: 72.01\nBatch: 701 / 782 Running Loss: 0.79 Running Accuracy: 72.41\nTraining: Epoch Loss: 0.78 Epoch Accuracy: 72.78\n--------------------------------------------------\nEpoch No: 2\nBatch: 1 / 782 Running Loss: 0.63 Running Accuracy: 78.12\nBatch: 101 / 782 Running Loss: 0.67 Running Accuracy: 76.76\nBatch: 201 / 782 Running Loss: 0.64 Running Accuracy: 77.24\nBatch: 301 / 782 Running Loss: 0.64 Running Accuracy: 77.57\nBatch: 401 / 782 Running Loss: 0.64 Running Accuracy: 77.66\nBatch: 501 / 782 Running Loss: 0.64 Running Accuracy: 77.7\nBatch: 601 / 782 Running Loss: 0.64 Running Accuracy: 77.7\nBatch: 701 / 782 Running Loss: 0.63 Running Accuracy: 77.76\nTraining: Epoch Loss: 0.63 Epoch Accuracy: 77.9\n--------------------------------------------------\nEpoch No: 3\nBatch: 1 / 782 Running Loss: 0.55 Running Accuracy: 78.12\nBatch: 101 / 782 Running Loss: 0.59 Running Accuracy: 79.02\nBatch: 201 / 782 Running Loss: 0.57 Running Accuracy: 79.65\nBatch: 301 / 782 Running Loss: 0.57 Running Accuracy: 79.82\nBatch: 401 / 782 Running Loss: 0.57 Running Accuracy: 79.89\nBatch: 501 / 782 Running Loss: 0.56 Running Accuracy: 80.02\nBatch: 601 / 782 Running Loss: 0.56 Running Accuracy: 80.07\nBatch: 701 / 782 Running Loss: 0.56 Running Accuracy: 80.12\nTraining: Epoch Loss: 0.56 Epoch Accuracy: 80.3\n--------------------------------------------------\nEpoch No: 4\nBatch: 1 / 782 Running Loss: 0.44 Running Accuracy: 82.81\nBatch: 101 / 782 Running Loss: 0.52 Running Accuracy: 81.67\nBatch: 201 / 782 Running Loss: 0.5 Running Accuracy: 82.19\nBatch: 301 / 782 Running Loss: 0.49 Running Accuracy: 82.52\nBatch: 401 / 782 Running Loss: 0.49 Running Accuracy: 82.69\nBatch: 501 / 782 Running Loss: 0.49 Running Accuracy: 82.81\nBatch: 601 / 782 Running Loss: 0.48 Running Accuracy: 82.82\nBatch: 701 / 782 Running Loss: 0.48 Running Accuracy: 82.96\nTraining: Epoch Loss: 0.48 Epoch Accuracy: 83.19\n--------------------------------------------------\nEpoch No: 5\nBatch: 1 / 782 Running Loss: 0.32 Running Accuracy: 84.38\nBatch: 101 / 782 Running Loss: 0.43 Running Accuracy: 85.09\nBatch: 201 / 782 Running Loss: 0.41 Running Accuracy: 85.35\nBatch: 301 / 782 Running Loss: 0.4 Running Accuracy: 85.63\nBatch: 401 / 782 Running Loss: 0.4 Running Accuracy: 85.8\nBatch: 501 / 782 Running Loss: 0.4 Running Accuracy: 86.02\nBatch: 601 / 782 Running Loss: 0.39 Running Accuracy: 86.1\nBatch: 701 / 782 Running Loss: 0.39 Running Accuracy: 86.23\nTraining: Epoch Loss: 0.39 Epoch Accuracy: 86.45\n--------------------------------------------------\nEpoch No: 1\nBatch: 1 / 782 Running Loss: 0.25 Running Accuracy: 92.19\nBatch: 101 / 782 Running Loss: 0.63 Running Accuracy: 80.03\nBatch: 201 / 782 Running Loss: 0.53 Running Accuracy: 83.06\nBatch: 301 / 782 Running Loss: 0.48 Running Accuracy: 84.57\nBatch: 401 / 782 Running Loss: 0.44 Running Accuracy: 85.67\nBatch: 501 / 782 Running Loss: 0.41 Running Accuracy: 86.61\nBatch: 601 / 782 Running Loss: 0.4 Running Accuracy: 86.99\nBatch: 701 / 782 Running Loss: 0.38 Running Accuracy: 87.53\nTraining: Epoch Loss: 0.37 Epoch Accuracy: 87.87\n--------------------------------------------------\nEpoch No: 2\nBatch: 1 / 782 Running Loss: 0.13 Running Accuracy: 95.31\nBatch: 101 / 782 Running Loss: 0.22 Running Accuracy: 92.48\nBatch: 201 / 782 Running Loss: 0.21 Running Accuracy: 92.96\nBatch: 301 / 782 Running Loss: 0.2 Running Accuracy: 93.05\nBatch: 401 / 782 Running Loss: 0.2 Running Accuracy: 93.26\nBatch: 501 / 782 Running Loss: 0.19 Running Accuracy: 93.4\nBatch: 601 / 782 Running Loss: 0.19 Running Accuracy: 93.49\nBatch: 701 / 782 Running Loss: 0.19 Running Accuracy: 93.62\nTraining: Epoch Loss: 0.18 Epoch Accuracy: 93.7\n--------------------------------------------------\nEpoch No: 3\nBatch: 1 / 782 Running Loss: 0.05 Running Accuracy: 98.44\nBatch: 101 / 782 Running Loss: 0.16 Running Accuracy: 94.51\nBatch: 201 / 782 Running Loss: 0.16 Running Accuracy: 94.38\nBatch: 301 / 782 Running Loss: 0.15 Running Accuracy: 94.58\nBatch: 401 / 782 Running Loss: 0.15 Running Accuracy: 94.63\nBatch: 501 / 782 Running Loss: 0.15 Running Accuracy: 94.66\nBatch: 601 / 782 Running Loss: 0.15 Running Accuracy: 94.68\nBatch: 701 / 782 Running Loss: 0.15 Running Accuracy: 94.68\nTraining: Epoch Loss: 0.15 Epoch Accuracy: 94.74\n--------------------------------------------------\nEpoch No: 4\nBatch: 1 / 782 Running Loss: 0.09 Running Accuracy: 95.31\nBatch: 101 / 782 Running Loss: 0.13 Running Accuracy: 95.54\nBatch: 201 / 782 Running Loss: 0.13 Running Accuracy: 95.44\nBatch: 301 / 782 Running Loss: 0.13 Running Accuracy: 95.5\nBatch: 401 / 782 Running Loss: 0.13 Running Accuracy: 95.46\nBatch: 501 / 782 Running Loss: 0.13 Running Accuracy: 95.57\nBatch: 601 / 782 Running Loss: 0.13 Running Accuracy: 95.56\nBatch: 701 / 782 Running Loss: 0.13 Running Accuracy: 95.66\nTraining: Epoch Loss: 0.12 Epoch Accuracy: 95.67\n--------------------------------------------------\nEpoch No: 5\nBatch: 1 / 782 Running Loss: 0.14 Running Accuracy: 95.31\nBatch: 101 / 782 Running Loss: 0.11 Running Accuracy: 96.04\nBatch: 201 / 782 Running Loss: 0.11 Running Accuracy: 96.11\nBatch: 301 / 782 Running Loss: 0.11 Running Accuracy: 96.13\nBatch: 401 / 782 Running Loss: 0.11 Running Accuracy: 96.19\nBatch: 501 / 782 Running Loss: 0.11 Running Accuracy: 96.3\nBatch: 601 / 782 Running Loss: 0.11 Running Accuracy: 96.31\nBatch: 701 / 782 Running Loss: 0.11 Running Accuracy: 96.37\nTraining: Epoch Loss: 0.1 Epoch Accuracy: 96.41\n--------------------------------------------------\n","output_type":"stream"}]},{"cell_type":"code","source":"shutil.unpack_archive('/kaggle/input/cifar-10/test.7z', '/kaggle/temp/')\n\n# shutil.register_unpack_format('7z')\n\nshutil.register_unpack_format('.7zip', '.7z', unpack_7zarchive)\n\n# shutil.unpack_archive('/kaggle/input/cifar-10/train.7z', '/kaggle/temp/')","metadata":{"execution":{"iopub.status.busy":"2024-04-29T06:00:04.110031Z","iopub.execute_input":"2024-04-29T06:00:04.110440Z","iopub.status.idle":"2024-04-29T06:03:18.754631Z","shell.execute_reply.started":"2024-04-29T06:00:04.110404Z","shell.execute_reply":"2024-04-29T06:03:18.753363Z"},"trusted":true},"execution_count":13,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRegistryError\u001b[0m                             Traceback (most recent call last)","Cell \u001b[0;32mIn[13], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m shutil\u001b[38;5;241m.\u001b[39munpack_archive(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/kaggle/input/cifar-10/test.7z\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/kaggle/temp/\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# shutil.register_unpack_format('7z')\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[43mshutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregister_unpack_format\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.7zip\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.7z\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munpack_7zarchive\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# shutil.unpack_archive('/kaggle/input/cifar-10/train.7z', '/kaggle/temp/')\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/shutil.py:1182\u001b[0m, in \u001b[0;36mregister_unpack_format\u001b[0;34m(name, extensions, function, extra_args, description)\u001b[0m\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m extra_args \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1181\u001b[0m     extra_args \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m-> 1182\u001b[0m \u001b[43m_check_unpack_options\u001b[49m\u001b[43m(\u001b[49m\u001b[43mextensions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1183\u001b[0m _UNPACK_FORMATS[name] \u001b[38;5;241m=\u001b[39m extensions, function, extra_args, description\n","File \u001b[0;32m/opt/conda/lib/python3.10/shutil.py:1156\u001b[0m, in \u001b[0;36m_check_unpack_options\u001b[0;34m(extensions, function, extra_args)\u001b[0m\n\u001b[1;32m   1154\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m extension \u001b[38;5;129;01min\u001b[39;00m existing_extensions:\n\u001b[1;32m   1155\u001b[0m         msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is already registered for \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m-> 1156\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m RegistryError(msg \u001b[38;5;241m%\u001b[39m (extension,\n\u001b[1;32m   1157\u001b[0m                                    existing_extensions[extension]))\n\u001b[1;32m   1159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(function):\n\u001b[1;32m   1160\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe registered function must be a callable\u001b[39m\u001b[38;5;124m'\u001b[39m)\n","\u001b[0;31mRegistryError\u001b[0m: . is already registered for \".7zip\""],"ename":"RegistryError","evalue":". is already registered for \".7zip\"","output_type":"error"}]},{"cell_type":"code","source":"class TestDataset(Dataset):\n    def __init__(self, imgpath):\n        super().__init__()\n        self.imgpath=imgpath\n        _,_,self.files=next(os.walk(self.imgpath))\n        self.length=len(self.files)\n        self.transform=Compose([Resize((224,224), antialias=True), Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])])        \n    \n    def __len__(self):\n        return self.length\n    \n    def __getitem__(self,idx):\n        finalpath=os.path.join(self.imgpath,str(idx+1))+'.png'\n        img=read_image(finalpath)/255.0\n        img=self.transform(img)\n        return img\n\ntestdataset=TestDataset('/kaggle/temp/test/')\ntestdataloader=DataLoader(dataset=testdataset, batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2024-03-20T14:54:55.531433Z","iopub.execute_input":"2024-03-20T14:54:55.531864Z","iopub.status.idle":"2024-03-20T14:54:55.872406Z","shell.execute_reply.started":"2024-03-20T14:54:55.531832Z","shell.execute_reply":"2024-03-20T14:54:55.871613Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"def eval(dataloader, model,loss_fn, path):\n    model.eval()\n    data=pd.read_csv(path)\n    with torch.no_grad():\n        for i, imgs in enumerate(dataloader):\n            finalbatchpred=np.zeros(imgs.shape[0],dtype='object')\n            imgs=imgs.to(device)\n            pred=model(imgs)\n            \n            pred=torch.argmax(pred,dim=1).type(torch.int).cpu()\n            for j,p in enumerate(pred):\n                finalbatchpred[j]=id_class[p.item()]\n            data.iloc[i*batch_size:i*batch_size+batch_size ,1]=finalbatchpred\n    \n    data.to_csv('submission.csv', index=False)\n    data.head()\n    \neval(testdataloader, model, loss, '/kaggle/input/cifar-10/sampleSubmission.csv')","metadata":{"execution":{"iopub.status.busy":"2024-03-20T14:54:59.555386Z","iopub.execute_input":"2024-03-20T14:54:59.556115Z","iopub.status.idle":"2024-03-20T15:03:01.731147Z","shell.execute_reply.started":"2024-03-20T14:54:59.556084Z","shell.execute_reply":"2024-03-20T15:03:01.730267Z"},"trusted":true},"execution_count":41,"outputs":[]}]}