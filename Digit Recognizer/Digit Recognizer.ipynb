{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#digit recongnizer"
      ],
      "metadata": {
        "id": "mN9Py4U0F2OI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9hKU2YDdfICv"
      },
      "outputs": [],
      "source": [
        "#Import statements\n",
        "import torch #Import the entire torch library\n",
        "from torch.utils.data import Dataset, DataLoader #Importing Dataset (Can create custom test and train dataset) and DataLoader (wrapper around Dataset to iterate)\n",
        "from torchvision.transforms import ToTensor #Transform function allows to convert PIL Images to numpy ndarray, normalize value between [0,1], and HxWxC to CxHxW\n",
        "import torch.nn as nn #Neural network from pytorch\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#finding best device on which we can run our tensor\n",
        "if torch.cuda.is_available():\n",
        "    device=torch.device(type=\"cuda\",index=0)#cuda is for GPU  and idx=0 means from multiple available GPUs assign first one i.e. at 0th idx one\n",
        "else:\n",
        "    device=torch.device(type=\"cpu\",index=0)#by defult it will run on CPU\n",
        "\n",
        "print(torch.cuda.is_available())\n",
        "\n",
        "print(device)\n",
        "#we have two ways either we create tensor on GPU or create on CPU and later on we can move it to GPU for computation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jeTF6G1kh-Fi",
        "outputId": "2181b640-a1c0-4751-d1d4-a488f52308a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomTrainDataset(Dataset):\n",
        "  def __init__(self, path, transform):#path is for train dataset\n",
        "    super().__init__()\n",
        "    self.data=pd.read_csv(path, header=\"infer\").values #header=\"infer\" means we are ignoring header and .values means we are creating into numpy array\n",
        "    self.length = self.data.shape[0] #shape means (row,col)\n",
        "    self.transform = transform\n",
        "\n",
        "  def __len__(self):\n",
        "      return self.length #returning already calculated length\n",
        "\n",
        "  def __getitem__(self, idx): # this is to set one input output pair at a time\n",
        "      flatimage = self.data[idx, 1:].astype(np.uint8) # means we are extracting ith image so it will have length 784\n",
        "      image = self.transform(np.reshape(flatimage, (28,28,1))) #converring into 2d image like (28*28*1)=784\n",
        "      label = self.data[idx,0]\n",
        "      return image, label # so we are returning 2d image and lable for that\n",
        "\n",
        "class CustomTestDataset(Dataset):# here we do not have any label for testing purpose so from 0th col to 783th col we have image vector\n",
        "  def __init__(self, path, transform):\n",
        "    super().__init__()\n",
        "    self.data = pd.read_csv(path, header=\"infer\").values\n",
        "    self.length = self.data.shape[0]\n",
        "    self.transform = transform\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.length\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    flatimage = self.data[idx,:].astype(np.uint8)\n",
        "    image = self.transform(np.reshape(flatimage, (28,28,1)))\n",
        "    return image\n",
        "\n",
        "train_dataset=CustomTrainDataset('/content/drive/MyDrive/Sem 6/DL/Practical-4/data/train.csv', ToTensor())\n",
        "test_dataset=CustomTestDataset('/content/drive/MyDrive/Sem 6/DL/Practical-4/data/test.csv', ToTensor())\n",
        "\n",
        "batch_size=64\n",
        "\n",
        "\n",
        "# now we have to wrap dataloader around our dataset so that it can divide dataset in to batch size of 64\n",
        "train_dl=DataLoader(\n",
        "    dataset=train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True\n",
        ")\n",
        "#here if we do shuffle then order of output will be distrubed but in submission we need in order so we are not applying shuffle\n",
        "test_dl=DataLoader(\n",
        "    dataset=test_dataset,\n",
        "    batch_size=batch_size,\n",
        ")\n",
        "#this class inherits nn.Module\n",
        "class DigitRecognizer(nn.Module):\n",
        "  #we are creating various layers we are not joining those  hence we can write lines of init method in any manner\n",
        "  def __init__(self): #dendor metod\n",
        "    super().__init__()\n",
        "    self.relu = nn.ReLU()#defining activation function and common for all layers\n",
        "\n",
        "    # first of all input will be 1x28x28 so channel will be 1 and we want to produce 8 channels.\n",
        "    self.conv1 = nn.Conv2d(in_channels=1, out_channels=8, kernel_size=(3,3), stride=1, padding=0)\n",
        "    self.bn1 = nn.BatchNorm2d(8) #8 -> because in output we are getting 8 channels so we need ot pass for 8 channges for normalisation\n",
        "    self.mp1 = nn.MaxPool2d(kernel_size=(2,2), stride=2, padding=0)\n",
        "\n",
        "    #here input channel is 8 because batchnorm.. and maxpooling not change to no of feature maps\n",
        "    self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=(3,3), stride=1, padding=0)\n",
        "    self.bn2 = nn.BatchNorm2d(16)\n",
        "\n",
        "    self.conv3 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(3,3), stride=1, padding=0)\n",
        "    self.bn3 = nn.BatchNorm2d(32)\n",
        "\n",
        "    self.conv4 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3,3), stride=1, padding=0)\n",
        "    self.bn4 = nn.BatchNorm2d(64)\n",
        "\n",
        "    self.flatten = nn.Flatten()\n",
        "\n",
        "    self.lin1 = nn.Linear(in_features=3136, out_features=10)#3136 is noting but 7*7*64\n",
        "    self.bn5 = nn.BatchNorm1d(num_features=10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # output=((w-f+2p)/s)+1\n",
        "    #so for first layer only we are applying maxpooling.\n",
        "    # so initialy x is 28x28\n",
        "    x = self.conv1(x) #now after applying stride and padding it will be 26x26\n",
        "    x = self.bn1(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.mp1(x) #now it will convert into 30x30\n",
        "\n",
        "    x = self.conv2(x) #now it will convert into 11x11\n",
        "    x = self.bn2(x)\n",
        "    x = self.relu(x)\n",
        "\n",
        "    x = self.conv3(x)#now it will be 9x9\n",
        "    x = self.bn3(x)\n",
        "    x = self.relu(x)\n",
        "\n",
        "    x = self.conv4(x)#now it will be 7x7 and 64 feature maps so\n",
        "    x = self.bn4(x)\n",
        "    x = self.relu(x)\n",
        "\n",
        "    x = self.flatten(x) #now after flatten it will be 7*7*64 means 3136\n",
        "\n",
        "    x = self.lin1(x) #and we are applying the linear conv so so output will be 10 features for each 64 images\n",
        "    output = self.bn5(x)\n",
        "\n",
        "    return output\n",
        "\n",
        "def train_one_epoch(dataloader, model,loss_fn, optimizer):\n",
        "    model.train()\n",
        "    track_loss=0\n",
        "    num_correct=0\n",
        "    for i, (imgs, labels) in enumerate(dataloader):\n",
        "        imgs=imgs.to(device)\n",
        "        labels=labels.to(device)\n",
        "        pred=model(imgs)#here it will be 64x1x28x28\n",
        "\n",
        "        loss=loss_fn(pred,labels)\n",
        "        track_loss+=loss.item()\n",
        "        num_correct+=(torch.argmax(pred,dim=1)==labels).type(torch.float).sum().item()\n",
        "\n",
        "        running_loss=round(track_loss/(i+(imgs.shape[0]/batch_size)),2)\n",
        "        running_acc=round((num_correct/((i*batch_size+imgs.shape[0])))*100,2)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if i%100==0:\n",
        "            print(\"Batch:\", i+1, \"/\",len(dataloader), \"Running Loss:\",running_loss, \"Running Accuracy:\",running_acc)\n",
        "\n",
        "    epoch_loss=running_loss\n",
        "    epoch_acc=running_acc\n",
        "    return epoch_loss, epoch_acc\n",
        "\n",
        "def eval(dataloader, model,loss_fn, path):\n",
        "    model.eval()\n",
        "    data=pd.read_csv(path) #it have image_id and predicted class\n",
        "    with torch.no_grad():\n",
        "        for i, imgs in enumerate(dataloader):#here i is batch size\n",
        "            imgs=imgs.to(device)\n",
        "            pred=model(imgs) #so here output will be 64x10\n",
        "\n",
        "            pred=torch.argmax(pred,dim=1).type(torch.int).cpu()#finding maximum pro idx for all 64 images\n",
        "            data.iloc[i*batch_size:i*batch_size+batch_size ,1]=pred.numpy() #now let i=0 so from [0:64] it will put predicted class using converting tensor to numpy like tensor.numpy()\n",
        "\n",
        "    data.to_csv('submission.csv', index=False)\n",
        "    data.head()\n",
        "\n",
        "\n",
        "\n",
        "model=DigitRecognizer()\n",
        "model=model.to(device)\n",
        "loss_fn=nn.CrossEntropyLoss()\n",
        "lr=0.001\n",
        "optimizer=torch.optim.Adam(params=model.parameters(), lr=lr)\n",
        "n_epochs=3\n",
        "\n",
        "for i in range(n_epochs):\n",
        "    print(\"Epoch No:\",i+1)\n",
        "    train_epoch_loss, train_epoch_acc=train_one_epoch(train_dl,model,loss_fn,optimizer)\n",
        "    print(\"Training:\", \"Epoch Loss:\", train_epoch_loss, \"Epoch Accuracy:\", train_epoch_acc)\n",
        "    print(\"--------------------------------------------------\")\n",
        "\n",
        "eval(test_dl, model,loss_fn, '/content/drive/MyDrive/Sem 6/DL/Practical-4/data/sample_submission.csv')"
      ],
      "metadata": {
        "id": "lpkv4vGXiNls",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69fa3da0-9c03-4edf-e620-34146e7d01a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch No: 1\n",
            "Batch: 1 / 657 Running Loss: 2.73 Running Accuracy: 3.12\n",
            "Batch: 101 / 657 Running Loss: 0.68 Running Accuracy: 89.98\n",
            "Batch: 201 / 657 Running Loss: 0.56 Running Accuracy: 93.06\n",
            "Batch: 301 / 657 Running Loss: 0.49 Running Accuracy: 94.41\n",
            "Batch: 401 / 657 Running Loss: 0.44 Running Accuracy: 95.26\n",
            "Batch: 501 / 657 Running Loss: 0.41 Running Accuracy: 95.79\n",
            "Batch: 601 / 657 Running Loss: 0.38 Running Accuracy: 96.22\n",
            "Training: Epoch Loss: 0.36 Epoch Accuracy: 96.39\n",
            "--------------------------------------------------\n",
            "Epoch No: 2\n",
            "Batch: 1 / 657 Running Loss: 0.15 Running Accuracy: 98.44\n",
            "Batch: 101 / 657 Running Loss: 0.19 Running Accuracy: 98.48\n",
            "Batch: 201 / 657 Running Loss: 0.18 Running Accuracy: 98.57\n",
            "Batch: 301 / 657 Running Loss: 0.17 Running Accuracy: 98.58\n",
            "Batch: 401 / 657 Running Loss: 0.17 Running Accuracy: 98.61\n",
            "Batch: 501 / 657 Running Loss: 0.16 Running Accuracy: 98.56\n",
            "Batch: 601 / 657 Running Loss: 0.16 Running Accuracy: 98.6\n",
            "Training: Epoch Loss: 0.15 Epoch Accuracy: 98.59\n",
            "--------------------------------------------------\n",
            "Epoch No: 3\n",
            "Batch: 1 / 657 Running Loss: 0.09 Running Accuracy: 100.0\n",
            "Batch: 101 / 657 Running Loss: 0.11 Running Accuracy: 98.82\n",
            "Batch: 201 / 657 Running Loss: 0.11 Running Accuracy: 98.8\n",
            "Batch: 301 / 657 Running Loss: 0.11 Running Accuracy: 98.82\n",
            "Batch: 401 / 657 Running Loss: 0.1 Running Accuracy: 98.87\n",
            "Batch: 501 / 657 Running Loss: 0.1 Running Accuracy: 98.9\n",
            "Batch: 601 / 657 Running Loss: 0.1 Running Accuracy: 98.91\n",
            "Training: Epoch Loss: 0.1 Epoch Accuracy: 98.9\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_kI5Eb0JWKkH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}